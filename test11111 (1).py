# -*- coding: utf-8 -*-
"""test11111.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iXMvkpEW6gPwcMUpDhCNUzEfm6c1_wYs

# IR
"""

!pip install qiskit qiskit-ibm-provider qiskit-aer matplotlib seaborn

"""### Prac-1"""

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
import re

corpus = ["HI! this is Nikhil Ingale.", "Currently pursuing Bachelors degree in AI&DS.", "My College is D.Y.Patil Institute of Technology, Pimpri."]
corpus

def preprocess(doc):
    doc = doc.lower()
    clean_doc = re.sub(r"[^a-zA-Z0-9]", " ", doc)
    tokens = word_tokenize(clean_doc)
    stop_words = stopwords.words('english')
    clean_tokens = [ token for token in tokens if token not in stop_words]

    return clean_tokens

processed_corpus = []
for doc in corpus:
    processed_corpus.append(preprocess(doc))

processed_corpus

stemmed_tokens = []
stemmer = PorterStemmer()
for doc in processed_corpus:
    temp = []
    for token in doc:
        stemmed_word = stemmer.stem(token)
        temp.append(stemmed_word)
    stemmed_tokens.append(temp)

stemmed_tokens

lemma_tokens = []
lemmatizer = WordNetLemmatizer()
for doc in processed_corpus:
    temp = []
    for token in doc:
        lemma_word = lemmatizer.lemmatize(token)
        temp.append(lemma_word)

    lemma_tokens.append(temp)

lemma_tokens

# OR
# [[lemmatizer.lemmatize(word) for word in doc] for doc in processed_corpus ]



"""## Prac-2"""

from collections import defaultdict
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
import re

corpus = {
    1: "This is the first document. It contains some text.",
    2: "The second document is longer. It also contains some text.",
    3: "This is the third document. It is different from the first two.",
}

stop_words = stopwords.words('english')
def preprocess(doc):
    doc = doc.lower()
    clean_doc = re.sub(r'[^A-Za-z0-9]', " ", doc)
    tokens = word_tokenize(clean_doc)
    clean_tokens = [token for token in tokens if token not in stop_words]

    return clean_tokens

inverted_index = defaultdict(list)
def create_index():
    for ind, doc in corpus.items():
        tokens = preprocess(doc)
        for token in tokens:
            inverted_index[token].append(ind)

create_index()
inverted_index

def process_query(query):
    tokens = preprocess(query)
    matched_docid = set()
    matched_docs = list()

    for token in tokens:
        if token in inverted_index:
            matched_docid.update(inverted_index[token])

    for doc_id in matched_docid:
        matched_docs.append(corpus[doc_id])

    return list(matched_docid), matched_docs

query = 'first document is good'
doc_id, docs = process_query(query)

for id, doc in zip(doc_id, docs):
    print(f"matched doc{id} : {doc} ")



"""## Prac-3"""

import pandas as pd
import numpy as np
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.inference import VariableElimination

df = pd.read_csv('dataset/heart.csv')
df.head()

df.shape

df.isna().sum()

model = BayesianNetwork(
    [('age','target'),
    ('sex','cp'),
    ('cp','target'),
    ('trestbps','target'),
    ('chol','target')]
)

model.fit(data=df, estimator=MaximumLikelihoodEstimator)

model.nodes

heartdiseasinfer = VariableElimination(model)

q1 = heartdiseasinfer.query(variables=['target'], evidence={'age':70})
print(q1)

q1 = heartdiseasinfer.query(variables=['target'], evidence={'cp':3})
print(q1)

import matplotlib.pyplot as plt
import networkx as nx
graph = nx.DiGraph()
graph.add_edges_from(model.edges())

plt.figure(figsize=(8, 6))
nx.draw(graph, with_labels=True, node_size=3000, node_color='lightblue', font_size=12, font_weight='bold', arrowsize=20)
plt.title("Bayesian Network Structure")
plt.show()



"""## Prac-4"""

import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sbn
import matplotlib.pyplot as plt

df = pd.read_csv('dataset/spam_ham_dataset.csv')
df.head()

df.drop(columns=['Unnamed: 0', 'label'], inplace=True)

df.isna().sum()

stop_words = stopwords.words('english')
def preprocess(doc):
    doc = doc.lower()
    clean_doc = re.sub(r'[^A-Za-z0-9]', " ", doc)
    tokens = word_tokenize(clean_doc)
    clean_tokens = [token for token in tokens if token not in stop_words]

    return " ".join(clean_tokens)

df['clean_text'] = df['text'].apply(preprocess)

df.drop(columns=['text'], inplace=True)
df.head()

X = df.iloc[:,1]
y = df.iloc[:,0]

vectorizer = CountVectorizer()
X_vectors = vectorizer.fit_transform(X)

X_vectors.toarray()

pd.DataFrame(data=X_vectors.toarray(), columns=vectorizer.get_feature_names_out())

vectorizer.get_feature_names_out()

vectorizer.vocabulary_

X_train, X_test, y_train, y_test= train_test_split(X_vectors, y, test_size=0.2, random_state=100)

model = MultinomialNB()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
cm

sbn.heatmap(cm, annot=True)

print(classification_report(y_pred, y_test))



"""## Prac-5"""

import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.decomposition import PCA

iris = load_iris()
X = iris.data
y = iris.target

scaler = StandardScaler()
X_scaled  = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

agg_cluster = AgglomerativeClustering(n_clusters=3, linkage='ward')
cluster_labels = agg_cluster.fit_predict(X_pca)

cluster_labels

linked = linkage(X_pca, 'ward')
plt.figure(figsize=(15,8))
dendrogram(linked, orientation='top', distance_sort='descending')
plt.show()

sbn.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=cluster_labels, palette='viridis')







"""# QAI

## Prac-1
"""

from qiskit_ibm_provider import IBMProvider
IBMProvider.save_account('e69b34162feb7f4676fa93dbcbd4ede189df708086bf35ba9bd859d60a10bb4ebdb142f6dfc746ad4fd72ce12e4d65f01cb63220fa8bb413b8aa5cd7f09bc389', overwrite=True)

from qiskit import QuantumCircuit, execute
from qiskit.visualization import circuit_drawer

circuit = QuantumCircuit(16,16)

circuit.h(range(16))

circuit.measure(range(16), range(16))

print(circuit)

circuit_drawer(circuit, output='mpl')

provider = IBMProvider()
simulator = provider.get_backend('ibm_brisbane')

job = execute(circuit, simulator, shots=1)

result = job.result()

counts = result.get_counts(circuit)

counts

# Extract the random number from the measurement outcome
random_number = int(list(counts.keys())[0], 2)

# Convert the random number to binary representation
binary_number = bin(random_number)[2:].zfill(16)

print("Random number (decimal):", random_number)
print("Random number (binary):", binary_number)

"""#### New way"""

from qiskit import QuantumCircuit, transpile
from qiskit import QuantumRegister, ClassicalRegister
from qiskit_aer import AerSimulator
from qiskit.visualization import plot_histogram

q = QuantumRegister(16, 'q')
c = ClassicalRegister(16, 'c')
circuit = QuantumCircuit(q, c)

circuit.h(q)
circuit.draw()
circuit.measure(q, c)
circuit.draw()

simulator = AerSimulator()

transpiled_circuit = transpile(circuit, simulator)
job = simulator.run(transpiled_circuit, shots=1)

print("Executing Job.....")
result = job.result()

counts = result.get_counts(circuit)
print("Result: ", counts)

"""## Prac-2"""

from qiskit import QuantumCircuit
from qiskit_aer import AerSimulator
from qiskit.visualization import plot_histogram
from qiskit_aer.noise import NoiseModel,depolarizing_error

qc=QuantumCircuit(3,3)

qc.h(0)
qc.cx(0,1)
qc.cx(0,2)
qc.measure([0,1,2],[0,1,2])

noise_model = NoiseModel()

# Add depolarizing noise for single-qubit gates and two-qubit gates
depol_1q = depolarizing_error(0.01, 1)
depol_2q = depolarizing_error(0.02, 2)
noise_model.add_all_qubit_quantum_error(depol_1q, ['u3', 'x', 'h'])
noise_model.add_all_qubit_quantum_error(depol_2q, ['cx'])

# Use AerSimulator and noise model for simulation
backend = AerSimulator()

# Execute the quantum circuit with noise model
result_with_noise = backend.run(qc,noise_model=noise_model, shots=1024).result()

# Get the raw counts with noise
noisy_counts = result_with_noise.get_counts(qc)

# Simple mitigation technique: scale counts based on expected noise
mitigated_counts = {key: noisy_counts[key] * (1 - 0.02) for key in noisy_counts}

# Plot the mitigated results
plot_histogram(mitigated_counts)

print("Original counts:")
print(noisy_counts)

print("Mitigated counts:")
print(mitigated_counts)

plot_histogram([noisy_counts, mitigated_counts], legend=['Original', 'Mitigated'])



"""## Prac-3"""

from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister,transpile
from qiskit.circuit.library import GroverOperator
from qiskit_aer import AerSimulator
import matplotlib.pyplot as plt
import seaborn as sns

def create_3_puzzle_circuit():
    """Create the quantum circuit for solving the 3-puzzle problem using Grover's algorithm."""
    # Initialize quantum and classical registers
    qr = QuantumRegister(3, 'q')
    cr = ClassicalRegister(3, 'c')
    qc = QuantumCircuit(qr, cr)

    # Initial state |000>
    # CNOT gates to exchange positions of qubits
    qc.cx(qr[0], qr[1])
    qc.cx(qr[1], qr[2])

    # Apply Hadamard gates to create superposition
    qc.h(qr[0])
    qc.h(qr[1])
    qc.h(qr[2])

    # Placeholder for Grover's algorithm
    # This requires defining an oracle and the Grover operator
    # Here we use a simple placeholder to illustrate the concept
    oracle = QuantumCircuit(3)
    oracle.z(0)  # Example oracle condition (adjust based on the puzzle's rules)
    oracle_gate = oracle.to_gate(label="Oracle")

    # Grover operator
    grover_operator = GroverOperator(oracle)
    qc.append(grover_operator, qr)

    # Measurement
    qc.measure(qr, cr)
    return qc

# Create the 3-puzzle quantum circuit
qc = create_3_puzzle_circuit()

# Execute the circuit on a quantum simulator
simulator = AerSimulator()
transpiled_qc = transpile(qc, simulator)

job = simulator.run(transpiled_qc, shots=1024)
result = job.result()
counts = result.get_counts()

# Output the result
print("Measurement results from the 3-puzzle quantum circuit:")
print(counts)

sns.barplot(x=list(counts.keys()), y=list(counts.values()))
plt.xlabel('Measurement Outcomes')
plt.ylabel('Counts')
plt.title('3-Puzzle Quantum Circuit Measurement Results')
plt.show()



"""## Prac-4"""

from qiskit.circuit import QuantumCircuit
from qiskit.visualization import plot_histogram
from qiskit_aer import AerSimulator
from qiskit import transpile

circuit = QuantumCircuit(3, 3)

circuit.x(0)
circuit.barrier(range(3))
circuit.h(1)
circuit.cx(1, 2)
circuit.cx(0, 1)
circuit.h(0)
circuit.barrier(range(3))
circuit.measure(range(2), range(2))
circuit.barrier(range(3))
circuit.cx(1, 2)
circuit.cz(0, 2)
circuit.draw()

backend = AerSimulator()
qc_compiled = transpile(circuit, backend)

job_sim = backend.run(qc_compiled, shots=1024)
result_sim = job_sim.result()

counts = result_sim.get_counts(qc_compiled)
print(counts)

plot_histogram(counts)



"""## Prac-5"""

import numpy as np
from qiskit import QuantumRegister, ClassicalRegister
from qiskit import QuantumCircuit,transpile
from qiskit_aer import AerSimulator

from qiskit.circuit.library import QFT

# Set up the AerSimulator backend
simulator = AerSimulator()

q = QuantumRegister(5,'q')
c = ClassicalRegister(5,'c')
circuit = QuantumCircuit(q,c)

circuit = QuantumCircuit(q, c)
circuit.h(q)

# Apply X gates to specific qubits (as per your original code)
circuit.x(q[4])
circuit.x(q[2])
circuit.x(q[0])

# Apply the Quantum Fourier Transform (QFT)
qft_circuit = QFT(num_qubits=5, approximation_degree=0, do_swaps=True, inverse=False, insert_barriers=False, name="qft")
circuit.append(qft_circuit, q)

circuit = circuit.compose(qft_circuit)
circuit.measure(q,c) # Measure the qubits and store the result in classical register
circuit.draw()

transpiled_circuit = transpile(circuit, simulator)
job = simulator.run(transpiled_circuit,shots=1000)

print("Job is running...")
print(f"Final job status: {job.status()}")

job_result = job.result()
counts = job_result.get_counts()
print("\n QFT Output")
print("-------------")
print(counts)

